{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "941f3540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eb70bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model_A= keras.models.load_model('fashion-mnist.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6623d23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5361e2",
   "metadata": {},
   "source": [
    "Note that model_A and model_B_on_A now share some layers. When you train\n",
    "model_B_on_A, it will also affect model_A. If you want to avoid that, you need to clone\n",
    "model_A before you reuse its layers. To do this, you must clone model A’s architecture,\n",
    "then copy its weights (since clone_model() does not clone the weights):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cdbc62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone=keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79cd259",
   "metadata": {},
   "source": [
    "Now we could just train model_B_on_A for task B, but since the new output layer was\n",
    "initialized randomly, it will make large errors, at least during the first few epochs, so\n",
    "there will be large error gradients that may wreck the reused weights. To avoid this,\n",
    "one approach is to freeze the reused layers during the first few epochs, giving the new\n",
    "layer some time to learn reasonable weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfe80efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable=False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b4efc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B_on_A.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bdbbc7",
   "metadata": {},
   "source": [
    "Next, we can train the model for a few epochs, then unfreeze the reused layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c0f7b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (12000, 28, 28)\n",
      "Test shape: (2000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "keep_classes = [5, 6]   \n",
    "\n",
    "train_mask = np.isin(y_train, keep_classes)\n",
    "test_mask  = np.isin(y_test, keep_classes)\n",
    "\n",
    "x_train_filtered = x_train[train_mask]\n",
    "y_train_filtered = y_train[train_mask]\n",
    "\n",
    "x_test_filtered = x_test[test_mask]\n",
    "y_test_filtered = y_test[test_mask]\n",
    "\n",
    "print(\"Train shape:\", x_train_filtered.shape)\n",
    "print(\"Test shape:\",  x_test_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84133494",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {5: 0, 6: 1}   # 0 = Sandal, 1 = Shirt\n",
    "\n",
    "y_train_filtered = np.array([label_map[y] for y in y_train_filtered])\n",
    "y_test_filtered  = np.array([label_map[y] for y in y_test_filtered])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b118f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train: (9600, 28, 28)\n",
      "Validation: (2400, 28, 28)\n",
      "Test: (2000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_final, x_val, y_train_final, y_val = train_test_split(\n",
    "    x_train_filtered, y_train_filtered, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_train_filtered  \n",
    ")\n",
    "\n",
    "print(\"Final Train:\", x_train_final.shape)\n",
    "print(\"Validation:\", x_val.shape)\n",
    "print(\"Test:\", x_test_filtered.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92bd94ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 8.1504 - val_accuracy: 0.9979 - val_loss: 3.6477\n",
      "Epoch 2/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9979 - loss: 3.3674 - val_accuracy: 0.9971 - val_loss: 3.4409\n",
      "Epoch 3/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9980 - loss: 2.8155 - val_accuracy: 0.9983 - val_loss: 2.8540\n",
      "Epoch 4/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9981 - loss: 1.9693 - val_accuracy: 0.9975 - val_loss: 2.0067\n",
      "Epoch 5/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 1.2592 - val_accuracy: 0.9987 - val_loss: 1.4406\n",
      "Epoch 6/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 1.0831 - val_accuracy: 0.9971 - val_loss: 2.6399\n",
      "Epoch 7/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9980 - loss: 0.8764 - val_accuracy: 0.9992 - val_loss: 0.8335\n",
      "Epoch 8/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.6003 - val_accuracy: 0.9987 - val_loss: 0.8264\n",
      "Epoch 9/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9979 - loss: 0.5274 - val_accuracy: 0.9987 - val_loss: 0.7489\n",
      "Epoch 10/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9983 - loss: 0.4702 - val_accuracy: 0.9975 - val_loss: 0.9571\n"
     ]
    }
   ],
   "source": [
    "history= model_B_on_A.fit(x_train_final , y_train_final ,epochs=10 , validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6453a3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    " layer.trainable = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03725667",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7054ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=optimizer,\n",
    " metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc81a838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.3219 - val_accuracy: 0.9983 - val_loss: 1.0056\n",
      "Epoch 2/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.1806 - val_accuracy: 0.9992 - val_loss: 0.8113\n",
      "Epoch 3/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 0.0044 - val_accuracy: 0.9987 - val_loss: 0.6974\n",
      "Epoch 4/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6395e-12 - val_accuracy: 0.9987 - val_loss: 0.6974\n",
      "Epoch 5/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6395e-12 - val_accuracy: 0.9987 - val_loss: 0.6974\n",
      "Epoch 6/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6395e-12 - val_accuracy: 0.9987 - val_loss: 0.6974\n",
      "Epoch 7/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6395e-12 - val_accuracy: 0.9987 - val_loss: 0.6974\n",
      "Epoch 8/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6395e-12 - val_accuracy: 0.9987 - val_loss: 0.6974\n",
      "Epoch 9/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6395e-12 - val_accuracy: 0.9987 - val_loss: 0.6974\n",
      "Epoch 10/10\n",
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6395e-12 - val_accuracy: 0.9987 - val_loss: 0.6974\n"
     ]
    }
   ],
   "source": [
    "history= model_B_on_A.fit(x_train_final , y_train_final ,epochs=10 , validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b93a142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1003 - loss: 3991.5696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3991.569580078125, 0.10029999911785126]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923a41c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (senalysis)",
   "language": "python",
   "name": "senalysis.venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
